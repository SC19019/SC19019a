---
title: "Introduction to SC19019"
author: "SC19019"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

__SC19019__ is a simple R package developed to show the Statistical Compute homework of student 19019. 
Two functions are considered, namely, _summary_result_ (Implement a paper) and _fc_ (Find the minimum number and it's index). For summary_result function, R version is produced. Namely _StatCompR_. For fc function, C++ version is produced. Namely _StatCompC_.

The source R code for _summary_result_ is:
```{r,eval=FALSE}
library(grf)
library(MASS)
options(digits=6)
m=50#m为样本个数
s=3#s为双尺度DNN的拐点
p=11#x的维数加上误差项的整体维数
nn=0
generate_fixed_point<-function(j)#构造出3_11个setting的固定测试点
{
  x<-rep(1,j)
  x<-x-1
  for(i in 3:j)
  {
    q=(i-1)%/%2
    x[q]=0.5
  }
  return(x)
}
generate_sample<-function(nn,m,p)#生成随机数函数，随机数种子随着每次循环发生改变
{
  set.seed(1234+nn)
  mean<-rep(1,p)
  sigma<-diag(mean)
  mean<-mean-1
  mydata<-mvrnorm(m,mean,sigma)
  w<-rbinom(m,1,0.5)
  z=cbind(mydata,w)
  return(z)#返回生成的随机矩阵，还未生成响应变量,p+1列是w，区分治疗以及没有治疗
}
#mydata=generate_sample(nn,m,p)  mydata第p列是白噪声
#head(mydata,n=5)
generate_setting1_2<-function(mydata,m,p)#生成设置一的响应y，p+2列是y
{
  x<-mydata[,1:(p-1)]
  w<-mydata[,(p+1)]
  if(p==4)
    y=(x[,1]-1)^2*w+(x[,2]+1)^3*w-3*x[,3]*w+mydata[,4]
  if(p==11)
    y=(x[,3]-1)^2*w+(x[,5]+1)^3*w-3*x[,7]*w+mydata[,11]
  z=cbind(mydata,y)
  return(z)#返回地一个设置中的x,w,y构成的矩阵
}
#生成3_11设置下的响应y，并且把y作为矩阵的最后一列
generate_setting3_11<-function(mydata,m,j)#mydata第j列为白噪声，j+1列是w
{
  y<-rep(1,m)
  y=y-1
  w<-mydata[,(j+1)]
  for(i in 1:(j-1))
  {
    y=y+((mydata[,i]^3-2*mydata[,i]^2+2*mydata[,i])^2)
  }
  y=log(y)*w+mydata[,j]
  z=cbind(mydata,y)
  return(z)#返回地一个设置中的x,w,y构成的矩阵
}
estimate_setting_DNN<-function(zz,mm,ss,x,p)#生成DNN估计量
{
  d<-matrix(nrow=mm,ncol=2)
  for(i in 1:mm)
  {
    d[i,1]=t(zz[i,1:(p-1)]-x)%*%(zz[i,1:(p-1)]-x)
  }
  d[,2]=zz[,(p+2)]
  pp=d[order(d[,1]),]	
  DNN=0
  for(i in 1:(mm-ss+1))
  {
    k=choose((mm-i),(ss-1))
    h=choose(mm,ss)
    DNN=DNN+k/h*pp[i,2]
  }
  
  return(DNN)
}#第一个设置中的DNN的计算

twoscaled_DNN<-function(zz,p,s,mm,xx)#当d为不同维度时候时候的双尺度DNN估计治疗效应,zz是x,w,y构成的矩阵
{
  z2<-data.frame(zz)
  data1<-subset(x=z2,z2$w==1)
  data2<-subset(x=z2,z2$w==0)
  new1<-as.matrix(data1)#治疗组
  new2<-as.matrix(data2)#对照组
  dd1<-dim(new1)
  dd2<-dim(new2)
  mm1=dd1[1]#治疗组样本个数
  mm2=dd2[1]#对照组样本个数
  dnn1_s=estimate_setting_DNN(new1,mm1,s,xx,p)
  ss=2*s
  dnn1_2s=estimate_setting_DNN(new1,mm1,ss,xx,p)
  kk1=1/(1-2^(2/(p-1)))
  kk2=-2^(2/(p-1))*kk1
  twoscales_dnn1=kk1*dnn1_s+kk2*dnn1_2s#治疗组双尺度DNN估计结果
  dnn2_s=estimate_setting_DNN(new2,mm2,s,xx,p)
  dnn2_2s=estimate_setting_DNN(new2,mm2,ss,xx,p)
  twoscales_dnn2=kk1*dnn2_s+kk2*dnn2_2s##对照组双尺度DNN估计结果
  
  effect=twoscales_dnn1-twoscales_dnn2
  return(effect)#返回治疗效果的估计值
}

generate_CF_sample<-function(mydata,m,p,x.test)
{
  x<-mydata[,1:(p-1)]
  w<-mydata[,(p+1)]
  y<-mydata[,(p+2)]
  c.forest=causal_forest(x,y,w)
  c.pred=predict(c.forest,t(x.test))#1*1的矩阵
  c.pre=c.pred[1,1]
  return(c.pre)
}
result_setting1_2<-function(m,s,p)
{
  estimate_result<-matrix(0,nrow=2,ncol=6)
  two_DNN<-vector("numeric",m)
  cf_mm<-vector("numeric",m)
  if(p==4)
    x.test<-c(0.5,-0.5,0.5)
  if(p==11)
    x.test<-c(0,0,0.5,0,-0.5,0,0.5,0,0,0)
  for(i in 1:m)
  {
    mydata=generate_sample(i,m,p)
    zz=generate_setting1_2(mydata,m,p)
    two_DNN[i]=twoscaled_DNN(zz,p,s,m,x.test)
    cf_mm[i]=generate_CF_sample(zz,m,p,x.test)
  } 
  if(p==4)
  {    
    y=(x.test[1]-1)^2+(x.test[2]+1)^3-3*x.test[3]
  } 
  if(p==11)
  {    
    y=(x.test[3]-1)^2+(x.test[5]+1)^3-3*x.test[7]
  } 
  
  estimate_result[1,1]=mean(two_DNN)-y
  estimate_result[2,1]=mean(cf_mm)-y
  estimate_result[1,2]=t(two_DNN-y)%*%(two_DNN-y)/m
  estimate_result[2,2]=t(cf_mm-y)%*%(cf_mm-y)/m
  estimate_result[1,3]=var(two_DNN)
  estimate_result[2,3]=var(cf_mm)
  
  two_DNN2<-vector("numeric",m)
  cf_mm2<-vector("numeric",m)
  x2.test<-runif((p-1), min = 0, max = 1)#生成随机检验的向量
  for(i in 2:(m+1))
  {
    mydata=generate_sample(i,m,p)
    zz=generate_setting1_2(mydata,m,p)
    two_DNN2[i]=twoscaled_DNN(zz,p,s,m,x2.test)
    cf_mm2[i]=generate_CF_sample(zz,m,p,x2.test)
  } 
  
  if(p==4)
    y2=(x2.test[1]-1)^2+(x2.test[2]+1)^3-3*x2.test[3]
  if(p==11)
    y2=(x2.test[3]-1)^2+(x2.test[5]+1)^3-3*x2.test[7]
  
  estimate_result[1,5]=mean(two_DNN2)-y2
  estimate_result[2,5]=mean(cf_mm2)-y2
  estimate_result[1,6]=t(two_DNN2-y2)%*%(two_DNN2-y2)/m
  estimate_result[2,6]=t(cf_mm2-y2)%*%(cf_mm2-y2)/m
  return(estimate_result)
}
generate_response3_11<-function(x,j)
{
  
  y=0
  for(i in 1:(j-1))
  {
    y=y+((x[i]^3-2*x[i]^2+2*x[i])^2)
  }
  y=log(y)
  return(y)
  
}
result_setting3_11<-function(m,s,p)
{
  estimate_result<-matrix(0,nrow=2,ncol=6)
  two_DNN<-vector("numeric",m)
  cf_mm<-vector("numeric",m)
  x.test=generate_fixed_point((p-1))
  for(i in 2:(m+1))
  {
    mydata=generate_sample(i,m,p)
    #head(mydata,n=5)
    zz=generate_setting3_11(mydata,m,p)
    #head(zz,n=5)
    two_DNN[i]=twoscaled_DNN(zz,p,s,m,x.test)
    cf_mm[i]=generate_CF_sample(zz,m,p,x.test)
  } 
  y=generate_response3_11(x.test,(p-1))
  estimate_result[1,1]=mean(two_DNN)-y
  # cfmm=as.vector(cf_mm)
  estimate_result[2,1]=mean(cf_mm)-y
  estimate_result[1,2]=t(two_DNN-y)%*%(two_DNN-y)/m
  estimate_result[2,2]=t(cf_mm-y)%*%(cf_mm-y)/m
  estimate_result[1,3]=var(two_DNN)
  estimate_result[2,3]=var(cf_mm)
  x2.test<-runif((p-1), min = 0, max = 1)#生成随机检验的向量
  two_DNN2<-vector("numeric",m)
  cf_mm2<-vector("numeric",m)
  for(i in 1:m)
  {
    mydata=generate_sample(i,m,p)
    zz=generate_setting3_11(mydata,m,p)
    two_DNN2[i]=twoscaled_DNN(zz,p,s,m,x2.test)
    cf_mm2[i]=generate_CF_sample(zz,m,p,x2.test)
  } 
  
  
  y2=generate_response3_11(x2.test,(p-1))
  estimate_result[1,5]=mean(two_DNN2)-y2
  estimate_result[2,5]=mean(cf_mm2)-y2
  estimate_result[1,6]=t(two_DNN2-y2)%*%(two_DNN2-y2)/m
  estimate_result[2,6]=t(cf_mm2-y2)%*%(cf_mm2-y2)/m
  return(estimate_result)
}
summary_result<-function(m,s)
{
  re1=result_setting1_2(m,s,4)
  re2=result_setting1_2(m,s,11)
  re=rbind(re1,re2)
  re3=result_setting3_11(m,s,11)
  re=rbind(re,re3)
  re4=result_setting3_11(m,s,16)
  re=rbind(re,re4)
  re5=result_setting3_11(m,s,21)
  re=rbind(re,re5) 
  re6=result_setting3_11(m,s,26)
  re=rbind(re,re6) 
  re7=result_setting3_11(m,s,31)
  re=rbind(re,re7) 
  re8=result_setting3_11(m,s,36)
  re=rbind(re,re8) 
  re9=result_setting3_11(m,s,41)
  re=rbind(re,re9) 
  re10=result_setting3_11(m,s,45)
  re=rbind(re,re10) 
  re11=result_setting3_11(m,s,51)
  re=rbind(re,re11) 
  return(re)
}
summary_result(50,3)
```

Input the sample size m and the subsample size s. Calculate estimates for all settings in that paper.Then Combine all the results and generate final results like the paper.The example as above.


The source R code for _fc_ is as follows:
```{r,eval=FALSE}
library(Rcpp) # Attach R package "Rcpp"
#find the index of min
cppFunction('List findmin(NumericVector x,int l){
double min=x[0];
int k;
for(int i=1;i<l;++i){
if(min>x[i]) {min=x[i];k=i+1;}
}
List s=List::create(min,k);
return s;
}')
a=c(1,2,3,0.4,5,6)
findmin(a,6)
```

Input a vector and it's length. Return the minimum element and it's index.The example as above.

## Homework

## Question
Use knitr to produce at least 3 examples(texts,figures,tables).

## Answer
Use Rmarkdown to produce html.Use knitr to produce 3 examples in the html.Each example includes texts,figures and tables.

## Example 1
Comparing frequency distribution and probability distribution by sampling size.

1.Generate 100 random numbers with normal distribution.

```{r}
a=rnorm(100,mean=0,sd=1)
summary(a)
```

Draw frequency histogram and density curve.

```{r}
hist(a, freq = F, breaks = 30)
lines(density(a, bw=.5), col="red", lwd=2)
```

2.Generate 1000 random numbers with normal distribution.

```{r}
b=rnorm(1000,mean=0,sd=1)
summary(b)
```

Draw frequency histogram and density curve.

```{r}
hist(b, freq = F, breaks = 30)
lines(density(b, bw=.5), col="red", lwd=2)
```

The result shows intuitively that the larger the sample, the closer the frequency distribution is to the overall probability distribution.

## Example 2

Research the mean of tne sum of two normal random variables with the same variance and different mean by sample.

```{r}
x1=rnorm(1000,1,1)
x2=rnorm(1000,3,1)
x3=x1+x2
mean(x3)
hist(x3, freq = F, breaks = 30)
lines(density(x3, bw=.5), col="red", lwd=2)
x4=cbind(x1,x2,x3)
library(knitr)
kable(head(x4),format="markdown")
```
The result shows The mean of the sum is the sum of the mean.

## Example 3
Using plot function.

```{r}
library(knitr)
y1=runif(100)
y2=rnorm(100)
y3=rexp(100)
y4=cbind(y1,y2,y3,y1^2,y2^2,y3^2)
kable(head(y4),format="markdown")
par(mar=c(1,1,1,1))
plot(y1,type="l",col="pink")
plot(y2,type="l",col="green")
plot(y3,type="l",col="yellow")
```

## Question1

The Rayleigh density [156, Ch. 18] is
$$
f(x)=\frac{x}{\sigma^{2}} e^{-x^{2} /\left(2 \sigma^{2}\right)}, \quad x \geq 0, \sigma>0
$$
Develop an algorithm to generate random samples from a Rayleigh(σ) distri-
bution. Generate Rayleigh(σ) samples for several choices of σ > 0 and check
that the mode of the generated samples is close to the theoretical mode σ
(check the histogram).

## Answer1

Use inverse transform method.First of all, integrate pdf f(x) to get cdf F(x).
$$
\begin{aligned} F(x) &=\int_{0}^{x} f(u) d u \\ &=\int_{0}^{x} \frac{u}{\sigma^{2}} e^{-u^{2} /(2 \sigma^{2})} d u \\ &=-\left.e^{-u^{2} /(2 \sigma^{2})}\right|_{0} ^{x} \\ &=1-e^{-x^{2}}\left(2 \sigma^{2}\right) \end{aligned}
$$

Next,Find the inverse function of F.
$$
F^{-1}(x)=\sqrt{-2 \sigma^{2} \ln (1-x)}
$$
Then,Generate uniform distributed random numbers u.$X=F^{-1}(u) \sim F(x)$ are what we need.

```{r}
n=10000                        #size of samples
f_sigma=function(sigma){            
  u=runif(n)
  x=sqrt(-2*sigma^2*log(1-u))
  x
}
```
f_sigma is a function to generate random samples from a Rayleigh(σ) distribution.

```{r}
par=(mar=c(1,1,1,1,1,1,1,1,1))
sigma=c(1,2,3,4,0.5,0.7,10.3,6.1,20)
for(i in 1:9){
x1=f_sigma(sigma[i])
hist(x1,prob=TRUE,main="Rayleigh density")
y <- seq(0, 100, .001)
lines(y, y/sigma[i]^2*exp(-y^2/(2*sigma[i]^2)),col="red")
}
```

I generate Rayleigh(σ) samples for 9 choices of σ > 0 and the results tell us the mode of the generated samples is close to the theoretical mode σ.


## Question2

Generate a random sample of size 1000 from a normal location mixture. The
components of the mixture have N(0,1) and N(3,1) distributions with mixing
probabilities p1 and p2 = 1 − p1 . Graph the histogram of the sample with
density superimposed, for p1 = 0.75. Repeat with different values for p1
and observe whether the empirical distribution of the mixture appears to be
bimodal. Make a conjecture about the values of p1 that produce bimodal
mixtures.

## Answer2

First,we definate a function mixture_p1 to generate a random sample of size 1000 from a normal location mixture. The components of the mixture have N(0,1) and N(3,1) distributions with mixing probabilities p1 and p2 = 1 − p1 .

```{r}
n=1000
mixture_p1=function(p1){
r=sample(c(0,1),size=n,replace=TRUE,prob=c(1-p1,p1))
#p1 for N(0,1),p2=1-p1 for N(3,1)
x1=rnorm(n,0,1)
x2=rnorm(n,3,1)
z=r*x1+(1-r)*x2
hist(z,,breaks=50,prob=TRUE)
lines(density(z),col="red")
}
```

Next, graph the histogram of the sample with density superimposed, for p1 = 0.75.

```{r}
mixture_p1(0.75)
```

Then,repeat with different values for p1 and observe whether the empirical distribution of the mixture appears to be bimodal.

```{r}
mixture_p1(0.05)
mixture_p1(0.15)
mixture_p1(0.25)
mixture_p1(0.35)
mixture_p1(0.45)
mixture_p1(0.55)
mixture_p1(0.65)
mixture_p1(0.85)
mixture_p1(0.95)
```

Based on these images,we have reason to guess that the closer P is to 0.5, the more obvious the bimodal distribution is.Repeat more.

```{r}
mixture_p1(0.37)
mixture_p1(0.4)
mixture_p1(0.43)
mixture_p1(0.47)
mixture_p1(0.5)
mixture_p1(0.53)
mixture_p1(0.57)
mixture_p1(0.6)
mixture_p1(0.63)
```

This result supports our conjecture.The closer P is to 0.5, the more obvious the bimodal distribution is.

## Question3

Write a function to generate a random sample from a Wd (Σ,n) (Wishart) distribution for n > d + 1 ≥ 1, based on Bartlett’s decomposition.

## Answer3
Based on Bartlett's decomposition,a variate X~Wd(Σ,n) can be write as X=LAA'L'.L is the cholesky factor of Σ.
$$
A=\left(\begin{array}{cccc}{c_{1}} & {0} & {\cdots} & {0} \\ {n_{21}} & {c_{2}} & {} & {\vdots} \\ {n_{31}} & {n_{32}} & {\ddots} & {\vdots} \\  {\vdots} &  {\vdots} & {} & {\vdots} \\{n_{d1}} & {n_{d2}} & {\cdots} & {c_{d}}\end{array}\right) , c_{i}^{2} \sim \chi_{n+1-i}^{2}, n_{i j} \sim N(0,1)
$$

Now,let's write the function which can generate a random sample from a Wd(Σ,n).
```{r}
wishart=function(sigma,n,d){
  if(n<d+2||d<0) print("please input integers n>d+1 and d>=0")
  else{
    A=matrix(numeric(d^2),d,d)
    for(i in 1:d){
      A[i,i]=sqrt(rchisq(1,n+1-i))
      for(j in 1:d){
        if(j<i) A[i,j]=rnorm(1)
        else if(j>i) A[i,j]=0
        else A[i,j]=A[i,i]
      }
    }#definate matrix A
    L=t(chol(sigma))  #Compute the Choleski factorization of sigma.
    X=L%*%A%*%t(A)%*%t(L)   #based on Bartlett's decompsition
  }
  X
}
```

Try this function with specific parameters.
```{r}
sigma=matrix(c(5,1,1,3),2,2)
d=2
n=4
wishart(sigma,n,d)
```

The result X is the random sample genereted by the function we write and x~Wd(Σ,n).

## Question1

Compute a Monte Carlo estimate of
$$
\int_{0}^{\pi / 3} \sin t d t
$$
and compare your estimate with the exact value of the integral.

## Answer1

$$
\int_{0}^{\pi / 3} \sin t d t=E\left(\frac{\pi}{3} \sin t\right), t\sim U\left(0, \frac{\pi}{3}\right)
$$
```{r}
set.seed(1)
m=1e4
x=runif(m,min=0,max=pi/3)
y=mean(pi/3*sin(x))
print(c(y,-cos(pi/3)+cos(0)))
```

The result shows my estimate is close to the exact value of the integral.

## Question2

Use Monte Carlo integration with antithetic variables to estimate
$$
\int_{0}^{1} \frac{e^{-x}}{1+x^{2}} d x
$$
and find the approximate reduction in variance as a percentage of the variance
without variance reduction.

## Answer2

$$
\begin{array}{l}{\theta=\int_{0}^{1} \frac{e^{-x}}{1+x^{2}} d x=E\left(\frac{e^{-x}}{1+x^{2}}\right), x \sim U(0,1)} \\ {\hat{\theta}=\frac{1}{m} \sum_{i=1}^{m / 2}\left(\frac{e^{-x_{i}}}{1+x_{i}^{2}}+\frac{e^{-\left(1-x_{i}\right)}}{1+\left(1-x_{i}\right)^{2}}\right), x_{i} \sim U(0,1)}\end{array}
$$

```{r}
set.seed(12)
m=1e4
x=runif(m)
x1=x[1:m/2]
u1=exp(-x1)/(1+x1^2)
u2=exp(-(1-x1))/(1+(1-x1)^2)
y1=(u1+u2)/2
theta.hat=mean(y1)#with variance reduction
y2=exp(-x)/(1+x^2)
theta.hat2=mean(y2) #without variance reduction
c(theta.hat,theta.hat2,var(y1),var(y2),1-var(y1)/var(y2))
```
The approximate reduction in variance as a percentage of the variance without variance reduction is 98.155%.

## Question3

Obtain the stratified importance sampling estimate in Example 5.13 and com-
pare it with the result of Example 5.10.

## Answer3

Divide the interval (0,1) into five subintervals, $(\alpha_{j-1},\alpha_j)$, $\alpha_j=F^{-1}(j/5)$ ,j = 1,...,5.F is the cdf of f3 in Example 5.13.
$$F=\frac{1-e^{-x}}{1-e^{-1}},0<x<1.$$
Then on the jth subinterval variables are generated from the density
$$\frac{5e^{-x}}{1-e^{-1}},\alpha_{j-1}<x<\alpha_j.$$

$$
\begin{array}{l}{\int_{0}^{1} \frac{e^{-x}}{1-e^{-1}} d x=\frac{1}{5} \sum_{j=1}^{5} \int_{\alpha_{j-1}}^{\alpha_j} \frac{5 e^{-x}}{1-e^{-1}} d x} \\ {g(x)=\frac{5 e^{-x}}{1-e^{-1}}} \\ {\int_{\alpha_{j-1}}^{\alpha_j} g(x)dx=\int_{0}^{1} \frac{g(x)}{f(x)} I\left(\alpha_{j-1}<x<\alpha_j\right) f(x) d x} \\ {\quad=E \frac{g(X)}{f(X)} I\left(\alpha_{j-1}<X<\alpha_j\right), X \sim f(x)}\end{array}
$$

```{r}
sub=function(a,b){#write a function for every subinterval to obtain importance sampling
m <- 10000
theta.hat <- se <- numeric(5)
g <- function(x) {
5*exp(-x - log(1+x^2))
}
u <- runif(m/5) #f3, inverse transform method
x <- - log(1 - u * (1 - exp(-1)))
fg <- g(x) / (exp(-x) / (1 - exp(-1)))*(x>a)*(x<b)
theta.hat <- mean(fg)
return(theta.hat)
}
```

```{r}
set.seed(54321)
alpha=c(0,0,0,0,0,1)#(0,1)分成五个子区间，第i个子区间的端点是(j-1)/5分位数和j/5分位数
for(j in 1:5){
  f=function(x)(1-exp(-x))/(1-exp(-1))-(j-1)/5
alpha[j]=uniroot(f,c(0,1))$root
}#求分位数
est=c(rep(0,50))
T=numeric(0)
for(i in 1:50){
for(j in 1:5)
  T[j]=sub(alpha[j],alpha[j+1])
  est[i]=mean(T)
}
c(mean(est),sd(est))
```
The stratified importance sampling estimate in Example 5.13 is 0.52278639,sd id smaller than Example 5.10.

## Question1
Suppose a 95% symmetric t-interval is applied to estimate a mean, but the
sample data are non-normal. Then the probability that the confidence interval
covers the mean is not necessarilyequal to 0.95. Use a Monte Carlo experiment
to estimate the coverage probability of the t-interval for random samples of
$\chi^2(2)$ data with sample size n = 20. Compare your t-interval results with the
simulation results in Example 6.4. (The t-interval should be more robust to
departures from normality than the interval for variance.)

## Answer1
### basic idea:
Generate random samples of Chi-Squared distribution with 2 degrees.Estimating mean value with t interval.Use a Monte Carlo experiment to estimate the coverage probability of the t-interval.Then compare the t-interval results with the simulation results in Example 6.4.

```{r}
set.seed(11)
alpha=0.05
n=20
x=rchisq(n,2)
s=sd(x)
l1=mean(x)-s/sqrt(n)*qt(1-alpha/2,n-1)
l2=mean(x)+s/sqrt(n)*qt(1-alpha/2,n-1)
c(l1,l2)
```

```{r}
set.seed(12)
m=1000
l1=l2=k=numeric(m)
for(i in 1:m){
x=rchisq(n,2)
s=sd(x)
l1[i]=mean(x)-s/sqrt(n)*qt(1-alpha/2,n-1)#卡方分布期望等于自由度
l2[i]=mean(x)+s/sqrt(n)*qt(1-alpha/2,n-1)
k[i]=(l1[i]<=2)*(2<=l2[i])
}
mean(k)
```

### conclusion
Through 1000 tests, the coverage probability is estimated to be 0.922.Compare the t-interval results with the simulation results in Example 6.4.The t-interval is smaller than the interval for variance.The t-interval is more robust to departures from normality than the interval for variance.

## Question2
Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles of the skewness $\sqrt b_1$ under
normality by a Monte Carlo experiment. Compute the standard error of the
estimates from (2.14) using the normal approximation for the density (with
exact variance formula). Compare the estimated quantiles with the quantiles
of the large sample approximation $\sqrt b_1$≈ N(0,6/n).

## Answer2
### basic idea:
First,Sampling from Standard Normal Distribution,calculate skewness for each sample.Use the sample quantile as the estimation value.
Second,use the normal approximation for the density (with exact variance formula) to Compute the standard error of the estimates.The normal approximation for the density is the density of N(0,6/n).
Third,Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt b_1$≈ N(0,6/n).

Write a function g(x) to generate skewness of random sample.
```{r}
g=function(x){
  a=mean((x-mean(x))^3)
  b=(mean((x-mean(x))^2))^(3/2)
  return(a/b)
}
```

Obtain samples.
```{r}
set.seed(3)
m=10000
n=200
b=numeric(m)
for(i in 1:m){
  x=rnorm(n)
  b[i]=g(x)
}
```

Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles.
```{r}
qb=numeric(4)
qb=quantile(b,probs=c(0.025,0.05,0.95,0.975))
qb
```

Compute the standard error.
```{r}
varb=function(q){
  xq=qnorm(q,0,sqrt(6/n))
  return(q*(1-q)/n/dnorm(xq,0,sqrt(6*(n-2)/(n+1)/(n+3)))^2)
}
q=c(0.025,0.05,0.95,0.975)
varb1=numeric(4)
for(i in 1:4)
  varb1[i]=varb(q[i])
sqrt(varb1)
```

Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt b_1$≈ N(0,6/n).
```{r}
qnorm(q,0,sqrt(6/n))
qb
```

### conclusion
The result shows that the estimated quantiles are close to the quantiles
of the large sample approximation $\sqrt b_1$≈ N(0,6/n).

## Question1
Efron and Tibshirani discuss the scor (bootstrap)test score data on 88 students who took examinations in five subjects [84, Table 7.1], [188, Table 1.2.1].The first two tests (mechanics, vectors) were closed book and the last three tests (algebra, analysis, statistics) were open book. Each row of the data frame is a set of scores (x i1 ,...,x i5 ) for the i th student. Use a panel display to display the scatter plots for each pair of test scores. Compare the plot with the sample correlation matrix. Obtain bootstrap estimates of the standard errors for each of the following estimates: $\hat\rho_{12} = \hat\rho(mec, vec)$, $\hat\rho_{34} = \hat\rho(alg,ana)$, $\hat\rho_{35} = \hat\rho(alg, sta)$, $\hat\rho_{45} = \hat\rho(ana, sta)$.

## Answer1
### basic idea
First,obtain scor data, and display the scatter plots for each pair of test scores.

Scend,caculate the sample correlation matrix, and compare the plot with the sample correlation matrix.

Third,Obtain bootstrap estimates of the standard errors estimates.

```{r}
library("bootstrap")
 plot(scor$mec,scor$vec)
 plot(scor$mec,scor$alg)
 plot(scor$mec,scor$ana)
 plot(scor$mec,scor$sta)
 plot(scor$vec,scor$alg)
 plot(scor$vec,scor$ana)
 plot(scor$vec,scor$sta)
 plot(scor$alg,scor$ana)
 plot(scor$alg,scor$sta)
 plot(scor$ana,scor$sta)
```  

Above are scatter plots for each pair of test scores.Scatter plots can visually show correlation.If the data is more correlated, the scatter plot will be more concentrated. We can see the plots of vec&alg, ana&alg and sta&alg are more concentrated , and they show that vec&alg, sat&ana, ana&alg and sta&alg are more correlated.

```{r}
cor(scor)
```

In the sample correlation matrix,the correlation coefficients of ana&alg, sta&alg, alg&vec and sta&ana are bigger than others.The bigger correlation coefficient shows more correlated.

### compare:
Scatter plots can visually show correlation.More concentrated means more correlated.Correlation matrix can accurately represent correlation.Bigger correlation coefficient means more correlated.Compare them,we can find the more concentrated scatter plots a pair data have, they will also have bigger correlation coefficient.The small correlation coefficient always with Scattered scatter plot.

```{r}
B=1e3
set.seed(123)
rho12=cor(scor$mec,scor$vec)
rho12star=rho34star=rho35star=rho45star=numeric(B)
for(b in 1:B){
  x1star=sample(1:nrow(scor),replace=TRUE)
  rho12star[b]=cor(scor$mec[x1star],scor$vec[x1star])
  rho34star[b]=cor(scor$alg[x1star],scor$ana[x1star])
  rho35star[b]=cor(scor$alg[x1star],scor$sta[x1star])
  rho45star[b]=cor(scor$ana[x1star],scor$sta[x1star])
}
se12.boot=sd(rho12star)
se34.boot=sd(rho34star)
se35.boot=sd(rho35star)
se45.boot=sd(rho45star)
print(c(se12.boot,se34.boot,se35.boot,se45.boot))
```

### Conclusion:
Scatter plots can visually show correlation.More concentrated means more correlated.Correlation matrix can accurately represent correlation.Bigger correlation coefficient means more correlated.Compare them,we can find the more concentrated scatter plots a pair data have, they will also have bigger correlation coefficient.The small correlation coefficient always with Scattered scatter plot.

The bootstrap estimates of the standard errors for each of the above estimates are 0.07718002, 0.04972798, 0.06256325 and 0.06986389.



## Question2
Repeat Project 7.A for the sample skewness statistic. Compare the coverage rates for normal populations (skewness 0) and $\chi^2\left(5\right)$ distributions (positive skewness).

## Answer2
### basic idea
First,repeat Project 7.A for the sample skewness statistic for normal populations (skewness 0) and $\chi^2\left(5\right)$ distributions (positive skewness).Obtain a sample from normal distribution and $\chi^2\left(5\right)$ distribution.Use bootstrap method to estimate the CI(standard normal,basic and percent).

Scend,use MC method to caculate the coverage rates.

Third,compare the coverage rates for normal populations and $\chi^2\left(5\right)$ distributions.


Write a function to estimate bootstrap CI(standard normal,basic and percent):
```{r}
g=function(x){
  a=mean((x-mean(x))^3)
  b=(mean((x-mean(x))^2))^(3/2)
  return(a/b)
}
m=100
alpha=0.05
CI=function(sample1,sample2,dist){ #The parameter dist is for selecting distribution and CI
b1=b2=numeric(m)
for(j in 1:m){
  x1=sample(sample1,replace=TRUE)
  x2=sample(sample2,replace=TRUE)
  b1[j]=g(x1)
  b2[j]=g(x2)
}
se1=sd(b1)
se2=sd(b2)
thetahat1=g(sample1)
thetahat2=g(sample2)
if(dist==11){
  CI1_stand=c(thetahat1-qnorm(1-alpha/2)*se1,thetahat1-qnorm(alpha/2)*se1)
  return(CI1_stand)
}
else if(dist==12){
  CI2_stand=c(thetahat2-qnorm(1-alpha/2)*se2,thetahat2-qnorm(alpha/2)*se2)
  return(CI2_stand)
}
else if(dist==21){
  CI1_basic=c(2*thetahat1-quantile(b1,probs=1-alpha/2),2*thetahat1-quantile(b1,probs=alpha/2))
  return(CI1_basic)
}
else if(dist==22){
  CI2_basic=c(2*thetahat2-quantile(b2,probs=1-alpha/2),2*thetahat2-quantile(b2,probs=alpha/2))
  return(CI2_basic)
  }
else if(dist==31){
  CI1_perc=c(quantile(b1,probs=alpha/2),quantile(b1,probs=1-alpha/2))
  return(CI1_perc)
}
else if(dist==32){
  CI2_perc=c(quantile(b2,probs=alpha/2),quantile(b2,probs=1-alpha/2))
  return(CI2_perc)
}
else cat("Error,dist should be included in{11,12,21,22,31,32}!","\n")
}
```

Caculate the true skewness:
```{r}
theta1=0
f=function(x) ((x-5)/sqrt(2*5))^3*dchisq(x,5)
theta2=integrate(f,0,Inf)$value
theta2#the true skewness of chisq
```

The empirical coverage rates for the bootstrap CI caculated by MC method:
```{r}
set.seed(2333)
ita=1000 #times of MC
test1=test2=matrix(numeric(9),ncol=3)#test1 for normal,test2 for chisq
colnames(test1)=colnames(test2)=c("cover","left_miss","right_miss")
rownames(test1)=rownames(test2)=c("normal_CI","basic_CI","perc_CI")
test11=test12=test21=test22=test31=test32=testl11=testl12=testl21=testl22=testl31=testl32=testr11=testr12=testr21=testr22=testr31=testr32=numeric(ita)
for(i in 1:ita){
  s1=rnorm(20)
  s2=rchisq(20,5)
  test11[i]=(CI(s1,s2,11)[1]<=theta1)*(CI(s1,s2,11)[2]>=theta1)
  test12[i]=(CI(s1,s2,12)[1]<=theta2)*(CI(s1,s2,12)[2]>=theta2)
  test21[i]=(CI(s1,s2,21)[1]<=theta1)*(CI(s1,s2,21)[2]>=theta1)
  test22[i]=(CI(s1,s2,22)[1]<=theta2)*(CI(s1,s2,22)[2]>=theta2)
  test31[i]=(CI(s1,s2,31)[1]<=theta1)*(CI(s1,s2,31)[2]>=theta1)
  test32[i]=(CI(s1,s2,32)[1]<=theta2)*(CI(s1,s2,32)[2]>=theta2)
  testl11[i]=(CI(s1,s2,11)[1]>=theta1);testl12[i]=(CI(s1,s2,12)[1]>=theta2);
  testl21[i]=(CI(s1,s2,21)[1]>=theta1);testl22[i]=(CI(s1,s2,22)[1]>=theta2);
  testl31[i]=(CI(s1,s2,31)[1]>=theta1);testl32[i]=(CI(s1,s2,32)[1]>=theta2);
  testr11[i]=(CI(s1,s2,11)[2]<=theta1);testr12[i]=(CI(s1,s2,12)[2]<=theta2);
  testr21[i]=(CI(s1,s2,21)[2]<=theta1);testr22[i]=(CI(s1,s2,22)[2]<=theta2);
  testr31[i]=(CI(s1,s2,31)[2]<=theta1);testr32[i]=(CI(s1,s2,32)[2]<=theta2)
}
test1[1,1]=mean(test11);test1[1,2]=mean(testl11);test1[1,3]=mean(testr11);
test1[2,1]=mean(test21);test1[2,2]=mean(testl21);test1[2,3]=mean(testr21);
test1[3,1]=mean(test31);test1[3,2]=mean(testl31);test1[3,3]=mean(testr31);
test2[1,1]=mean(test12);test2[1,2]=mean(testl12);test2[1,3]=mean(testr12);
test2[2,1]=mean(test22);test2[2,2]=mean(testl22);test2[2,3]=mean(testr22);
test2[3,1]=mean(test32);test2[3,2]=mean(testl32);test2[3,3]=mean(testr32)
#For normal population:
test1
#For $\chi^2\left(5\right)$ population:
test2
```

### Conclusion:
1.For normal populations

The coverage rates for the normal CI and the percentile CI are bigger than the basic CI.So the standard normal bootstrap CI and the percentile bootstrap CI are better than the basic bootstrap CI for normal populations.

In every CI estimating method,the proportion of times that the confidence intervals miss on the left is about equal to the porportion of times that the confidence intervals miss on the right.

2.For $\chi^2\left(5\right)$ population

The coverage rate for the normal CI is bigger than the percentile CI and the basic CI.But all are not very big.For normal CI and perc CI,the proportion of times that the confidence intervals miss on the left is smaller than right.For basic CI,the proportion of times that the confidence intervals miss on the left is bigger than right.

####  Compare the coverage rates for normal populations and $\chi^2\left(5\right)$ distributions:
For each of normal CI,basic CI and percentile CI,the coverage rates for normal populations are bigger than $\chi^2\left(5\right)$ distributions.

## Question1
Estimate the power of the skewness test of normality against symmetric Beta(α,α) distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as t(ν)?

## Answer1
### Basic idea:
First,Estimate the power of the skewness test of normality against symmetric Beta(α,α) distributions and comment on the results.
Second,Estimate the power of the skewness test of normality against t(ν) distributions and comment on the results.
Third,compare them.

Write a function g(x) to generate skewness of random sample.
```{r}
g=function(x){
  a=mean((x-mean(x))^3)
  b=(mean((x-mean(x))^2))^(3/2)
  return(a/b)
}
```

Estimate the power of the skewness test of normality against symmetric Beta(α,α) distributions.
```{r}
f=function(alpha,a){
n=30
m=1000
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sktests <- numeric(m)
for (i in 1:m) { #for each replicate
  x=rbeta(n,a,a)
  sktests[i] <- as.integer(abs(g(x)) >= cv)
}
pwr <- mean(sktests)
return(pwr)
}
```

Calculate some results.
```{r}
set.seed(1)
a=seq(1,20,1)
Pwr=matrix(c(rep(0,60)),nrow=3)
alpha=c(0.05,0.07,0.1)
for(i in 1:3)
for(j in 1:20)
  Pwr[i,j]=f(alpha[i],a[j])
Pwr
```
Comment1:The power is too small.So the skewness test of normality is not suitable for symmetric Beta(α,α) distributions.


Estimate the power of the skewness test of normality against t(v) distributions.
```{r}
f2=function(alpha,v){
n=30
m=1000
cv <- qnorm(1-alpha/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))
sktests <- numeric(m)
for (i in 1:m) { #for each replicate
  x=rt(n,v)
  sktests[i] <- as.integer(abs(g(x)) >= cv)
}
pwr <- mean(sktests)
return(pwr)
}
```

Calculate some results.
```{r}
set.seed(2)
v=seq(1,20,1)
Pwr2=matrix(c(rep(0,60)),nrow=3)
alpha=c(0.05,0.07,0.1)
for(i in 1:3)
for(j in 1:20)
  Pwr2[i,j]=f2(alpha[i],v[j])
Pwr2
```
Comment2:The results are different for heavy-tailed symmetric alternatives such as t(ν).The power of t(v) is larger.

## Conclusion
The skewness test of normality is suitable for t(v) distributions,but not suitable for Beta(α,α).


## Question2
Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α, when the sampled population is non-normal. The t-test is robust to milddepartures from normality. Discuss the simulation results for the cases where the sampled population is (i)$\chi^2(1)$, (ii) Uniform(0,2), and (iii) Exponential(rate=1). In each case, test H0 : µ = µ0 vs H1 : µ != µ0 , where µ0 is the mean of $\chi^2(1)$, Uniform(0,2), and Exponential(1), respectively.

## Answer2
## Basic idea:
First,use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α, when the sampled population is $\chi^2(1)$.
Second,use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α, when the sampled population is Uniform(0,2).
Third,use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α, when the sampled population is Exponential(1).
Each simulation was performed three times for three different alpha.


For $\chi^2(1)$.The mean is 1.
```{r}
set.seed(21)
alpha=0.025
m <- 10000
n=20
test1 <- numeric(m) #test decisions
for (j in 1:m) {
x1 <- rchisq(n,1)
s1=sd(x1)
#test decision is 1 (reject) or 0
l1=1-s1/sqrt(n)*qt(1-alpha/2,n-1)
l2=1+s1/sqrt(n)*qt(1-alpha/2,n-1)
test1[j] <- 1-(mean(x1) >=l1 )*(mean(x1) <=l2)
}
p.reject1 <- mean(test1) #proportion rejected
p.reject1
```
```{r}
set.seed(21)
alpha=0.05
m <- 10000
n=20
test1 <- numeric(m) #test decisions
for (j in 1:m) {
x1 <- rchisq(n,1)
s1=sd(x1)
#test decision is 1 (reject) or 0
l1=1-s1/sqrt(n)*qt(1-alpha/2,n-1)
l2=1+s1/sqrt(n)*qt(1-alpha/2,n-1)
test1[j] <- 1-(mean(x1) >=l1 )*(mean(x1) <=l2)
}
p.reject1 <- mean(test1) #proportion rejected
p.reject1
```
```{r}
set.seed(21)
alpha=0.1
m <- 10000
n=20
test1 <- numeric(m) #test decisions
for (j in 1:m) {
x1 <- rchisq(n,1)
s1=sd(x1)
#test decision is 1 (reject) or 0
l1=1-s1/sqrt(n)*qt(1-alpha/2,n-1)
l2=1+s1/sqrt(n)*qt(1-alpha/2,n-1)
test1[j] <- 1-(mean(x1) >=l1 )*(mean(x1) <=l2)
}
p.reject1 <- mean(test1) #proportion rejected
p.reject1
```

For Uniform(0,2).The mean is 1.
```{r}
set.seed(22)
alpha=0.025
m <- 10000 
n=20
test2 <- numeric(m) #test decisions
for (j in 1:m) {
x2 <- runif(n,min=0,max=2)
s2=sd(x2)
l21=1-s2/sqrt(n)*qt(1-alpha/2,n-1)
l22=1+s2/sqrt(n)*qt(1-alpha/2,n-1)
test2[j] <- 1-(mean(x2) >=l21 )*(mean(x2) <=l22)
}
p.reject2 <- mean(test2) #proportion rejected
p.reject2
```

```{r}
set.seed(22)
alpha=0.05
m <- 10000 
n=20
test2 <- numeric(m) #test decisions
for (j in 1:m) {
x2 <- runif(n,min=0,max=2)
s2=sd(x2)
l21=1-s2/sqrt(n)*qt(1-alpha/2,n-1)
l22=1+s2/sqrt(n)*qt(1-alpha/2,n-1)
test2[j] <- 1-(mean(x2) >=l21 )*(mean(x2) <=l22)
}
p.reject2 <- mean(test2) #proportion rejected
p.reject2
```
```{r}
set.seed(22)
alpha=0.1
m <- 10000 
n=20
test2 <- numeric(m) #test decisions
for (j in 1:m) {
x2 <- runif(n,min=0,max=2)
s2=sd(x2)
l21=1-s2/sqrt(n)*qt(1-alpha/2,n-1)
l22=1+s2/sqrt(n)*qt(1-alpha/2,n-1)
test2[j] <- 1-(mean(x2) >=l21 )*(mean(x2) <=l22)
}
p.reject2 <- mean(test2) #proportion rejected
p.reject2
```

For Exponential(1).The mean is 1.
```{r}
set.seed(23)
alpha=0.025
m <- 10000 
n=20
test3 <- numeric(m) #test decisions
for (j in 1:m) {
x3 <- rexp(n,1)
s3=sd(x3)
l31=1-s3/sqrt(n)*qt(1-alpha/2,n-1)
l32=1+s3/sqrt(n)*qt(1-alpha/2,n-1)
test3[j] <- 1-(mean(x3) >=l31 )*(mean(x3) <=l32)
}
p.reject3 <- mean(test3) #proportion rejected
p.reject3
```
```{r}
set.seed(23)
alpha=0.05
m <- 10000 
n=20
test3 <- numeric(m) #test decisions
for (j in 1:m) {
x3 <- rexp(n,1)
s3=sd(x3)
l31=1-s3/sqrt(n)*qt(1-alpha/2,n-1)
l32=1+s3/sqrt(n)*qt(1-alpha/2,n-1)
test3[j] <- 1-(mean(x3) >=l31 )*(mean(x3) <=l32)
}
p.reject3 <- mean(test3) #proportion rejected
p.reject3
```
```{r}
set.seed(23)
alpha=0.1
m <- 10000 
n=20
test3 <- numeric(m) #test decisions
for (j in 1:m) {
x3 <- rexp(n,1)
s3=sd(x3)
l31=1-s3/sqrt(n)*qt(1-alpha/2,n-1)
l32=1+s3/sqrt(n)*qt(1-alpha/2,n-1)
test3[j] <- 1-(mean(x3) >=l31 )*(mean(x3) <=l32)
}
p.reject3 <- mean(test3) #proportion rejected
p.reject3
```

### Conclusion
For Uniform(0,2), the empirical Type I error rate of the t-test is approximately equal to the nominal significance level α.
For $\chi^2(1)$ and Exponential(1),the empirical Type I error rate of the t-test are not approximately equal to the nominal significance level α.



## Question3
Discussion:
If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are diﬀerent at 0.05 level?

1.What is the corresponding hypothesis test problem?

2.What test should we use? Z-test, two-sample t-test, paired-t test or McNemar test?

3.What information is needed to test your hypothesis?

## Answer3
1.$H_0:power1= power2\quad vs\quad H_1:power1 \neq power2$.
The power1 is the power of method1.The power2 is the power of method2.

2.We should use McNemar test.Because Z-test and t-test require sample form normal distribution.McNemar test can check whether the ratio has changed before and after the incident.The power is s kind of ratio.We can think two methods as "before and after the incident".So we can use McNemar test to check this problem.

3.The information needed to test my hypothesis is:
The experiment times of method1 based on H1 reject H0 and method2 based on H0 reject H0.
The experiment times of method1 based on H0 reject H0 and method2 based on H1 reject H0.

## Question1
Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard
error of $\hat \theta$.

## Answer1
### basic idea:
1.Use leave-one-out method to obtain Jackknife sample.

2.Caculate $\hat \theta_{(i)}$.

3.Obtain the jackknife estimates of bias and standard error of $\hat \theta$.

```{r}
library("bootstrap")
n=nrow(scor)
sigma.hat=(n-1)/n*cor(scor)
lambda.hat=eigen(sigma.hat)$values
theta.hat=lambda.hat[1]/sum(lambda.hat)
theta.jack=numeric(n)
for(i in 1:n){
  sigma=(n-2)/(n-1)*cor(scor[-i,])
  lambda=eigen(sigma)$values
  theta.jack[i]=lambda[1]/sum(lambda)
}
#An unbiased estimate of bias
esti.bias=(n-1)*(mean(theta.jack)-theta.hat)
#An estimate of standard error
esti.se=sqrt((n-1)*mean((theta.jack-mean(theta.jack))^2))
cat("The jackknife estimate of bias is",esti.bias,"\n",
    "The jackknife estimate of standard error is",esti.se,"\n")
```

### Conclusion
The jackknife estimates of bias and standard error of $\hat \theta$ are above.


## Question2
In Example 7.18, leave-one-out (n-fold) cross validation was used to select
the best fitting model. Repeat the analysis replacing the Log-Log model
with a cubic polynomial model. Which of the four models is selected by the
cross validation procedure? Which model is selected according to maximum
adjusted $R^2$?

## Answer2
### basic idea
Repeat the analysis replacing the Log-Log model with a cubic polynomial model.The proposed models for predicting magnetic measurement (Y) from chemical measurement (X) are:

1. Linear: $Y = β_0 + β_1X + ε$.

2. Quadratic: $Y = β_0 + β_1X + β_2X^2 + ε$.

3. Exponential: $log\left(Y \right) = log\left(β_0\right) + β_1X + ε$.

4. cubic polynomial:  $Y = β_0 + β_1X + β_2X^2 +β_3X^3+ ε$.

Plots of the predicted response with the data are also constructed for each model.

```{r}
library("DAAG")
attach(ironslag)
a <- seq(10, 40, .1) #sequence for plotting fits
L1 <- lm(magnetic ~ chemical)
plot(chemical, magnetic, main="Linear", pch=16)
yhat1 <- L1$coef[1] + L1$coef[2] * a
lines(a, yhat1, lwd=2)
L2 <- lm(magnetic ~ chemical + I(chemical^2))
plot(chemical, magnetic, main="Quadratic", pch=16)
yhat2 <- L2$coef[1] + L2$coef[2] * a + L2$coef[3] * a^2
lines(a, yhat2, lwd=2)
L3 <- lm(log(magnetic) ~ chemical)
plot(chemical, magnetic, main="Exponential", pch=16)
logyhat3 <- L3$coef[1] + L3$coef[2] * a
yhat3 <- exp(logyhat3)
lines(a, yhat3, lwd=2)
L4 <- lm(magnetic ~ chemical + I(chemical^2)+I(chemical^3))
plot(chemical, magnetic, main="cubic polynomial", pch=16)
yhat4 <- L4$coef[1] + L4$coef[2] * a+ L4$coef[3] * a^2++ L4$coef[4] * a^3
lines(a, yhat4, lwd=2)
```

Use leave-one-out (n-fold) cross validation to select the best fitting model.
```{r}
n <- length(magnetic) #in DAAG ironslag
e1 <- e2 <- e3 <- e4 <- numeric(n)
# for n-fold cross validation
# fit models on leave-one-out samples
for (k in 1:n) {
y <- magnetic[-k]
x <- chemical[-k]
J1 <- lm(y ~ x)
yhat1 <- J1$coef[1] + J1$coef[2] * chemical[k]
e1[k] <- magnetic[k] - yhat1
J2 <- lm(y ~ x + I(x^2))
yhat2 <- J2$coef[1] + J2$coef[2] * chemical[k] +J2$coef[3] * chemical[k]^2
e2[k] <- magnetic[k] - yhat2
J3 <- lm(log(y) ~ x)
logyhat3 <- J3$coef[1] + J3$coef[2] * chemical[k]
yhat3 <- exp(logyhat3)
e3[k] <- magnetic[k] - yhat3
J4 <- lm(y ~ x + I(x^2)+I(x^3))
yhat4 <- J4$coef[1] + J4$coef[2] * chemical[k] +J4$coef[3] * chemical[k]^2+J4$coef[4] * chemical[k]^3
e4[k] <- magnetic[k] - yhat4
}
```
The following estimates for prediction error are obtained from the n-fold cross validation.

```{r}
c(mean(e1^2), mean(e2^2), mean(e3^2), mean(e4^2))
```
### conclusion1
According to the prediction error criterion, Model 2, the quadratic model,
would be the best fit for the data.

```{r}
L2
```

The fitted regression equation for Model 2 is $\hat Y= 24.49262 − 1.39334X + 0.05452X^2$.

```{r}
adj.r.squa=numeric(4)
adj.r.squa[1]=summary(L1)$adj.r.squared
adj.r.squa[2]=summary(L2)$adj.r.squared
adj.r.squa[3]=summary(L3)$adj.r.squared
adj.r.squa[4]=summary(L4)$adj.r.squared
c(adj.r.squa[1],adj.r.squa[2],adj.r.squa[3],adj.r.squa[4])
```

### conclusion2
According to maximum adjusted $R^2$, Model 2, the quadratic model, would be the best fit for the data.Since the adjusted $R^2$ of Model 4 is closed to Model 2, we can say that both model 2 and model 4 are the best fits for the data in a small range of fluctuation.

```{r}
L4
```

The fitted regression equation for Model 2 is $\hat Y= 24.49262 − 1.39334X + 0.05452X^2$.

The fitted regression equation for Model 3 is $\hat Y= 3.01585 + 1.91808X -0.10796X^2+0.00255x^3$.

## Question1

The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.

## Answer1

Treat two samples as one without difference.Conduct Count 5 test.

```{r}
count5test_new = function(z) {
n = length(z)
x = z[1:(n/2)]
y = z[-(1:(n/2))]
X = x - mean(x)
Y = y - mean(y)
outx = sum(X > max(Y)) + sum(X < min(Y)) 
outy = sum(Y > max(X)) + sum(Y < min(X))
# return 1 (reject) or 0 (do not reject H0) 
return(as.integer(max(c(outx, outy)) > 5))
}
perm = function(z,R) {
  n = length(z)
  out = numeric(R)
  for (r in 1: R){
      p = sample(1:n ,n ,replace = FALSE)
      out[r] = count5test_new(z[p])
  }
  sum(out)/R
}              
n1 = 20
n2 = 50
mu1 = mu2 = 0
sigma1 = sigma2 = 1
m = 1e3
set.seed(1122)
alphahat = mean(replicate(m, expr={
x = rnorm(n1, mu1, sigma1)
y = rnorm(n2, mu2, sigma2)
x = x - mean(x) #centered by sample mean 
y = y - mean(y)
z = c(x,y)
perm(z,1000) 
})<0.05)
round(alphahat,4)
```

### Conclusion

The result is smaller than example6.15.And this is reasonable.

## Question2

Slides page31.Power compasion(distance correlation test versus ball covariance test)

Model 1:$Y=X/4+e$

Model 2:$Y=X/4*e$

$X\sim N(0_2,I_2),e\sim N(0_2,I_2)$,$X$ and $e$ are independent.

## Answer2

Use the ways in the slides.
```{r}
library(MASS)
library(Ball)
library(boot)
dCov <- function(x, y) {
x <- as.matrix(x); y <- as.matrix(y)
n <- nrow(x); m <- nrow(y)
if (n != m || n < 2) stop("Sample sizes must agree")
if (! (all(is.finite(c(x, y)))))
stop("Data contains missing or infinite values")
Akl <- function(x) {
d <- as.matrix(dist(x))
m <- rowMeans(d); M <- mean(d)
a <- sweep(d, 1, m); b <- sweep(a, 2, m)
b + M
}
A <- Akl(x); B <- Akl(y)
sqrt(mean(A * B))
}
ndCov2 <- function(z, ix, dims) {
#dims contains dimensions of x and y
p <- dims[1]
q <- dims[2]
d <- p + q
x <- z[ , 1:p] #leave x as is
y <- z[ix, -(1:p)] #permute rows of y
return(nrow(z) * dCov(x, y)^2)
}
n = seq(20,200,20)
m = 100

p.cor = matrix(0,length(n),2)
p.ball = matrix(0,length(n),2)

for (i in 1:length(n)){
 
  p.cor_sim = matrix(0, m, 2)
  p.ball_sim = matrix(0, m, 2)

  for (j in 1:m){
    set.seed(12345+j)
    x = mvrnorm(n[i],mu=rep(0,2),Sigma=diag(rep(1,2)))
    e = mvrnorm(n[i],mu=rep(0,2),Sigma=diag(rep(1,2)))
    y1 = x/4 + e
    y2 = x/4*e
    #model1
    boot.obj1 = boot(data = cbind(x,y1), statistic = ndCov2, R = 99, sim = "permutation", dims = c(2, 2))
    #permutatin: resampling without replacement
    tb1 = c(boot.obj1$t0, boot.obj1$t)
    p.cor_sim[j,1] = mean(tb1>=tb1[1])
    p.ball_sim[j,1] = bcov.test(x,y1,num.permutations=99,seed=j)$p.value
    #model2
    boot.obj2 = boot(data = cbind(x,y2), statistic = ndCov2, R = 99, sim = "permutation", dims = c(2, 2))
    #permutatin: resampling without replacement
    tb2 = c(boot.obj2$t0, boot.obj2$t)
    p.cor_sim[j,2] = mean(tb2>=tb2[1])
    p.ball_sim[j,2] = bcov.test(x,y2,num.permutations =99,seed=j)$p.value
  }
  p.cor[i,] = colMeans(p.cor_sim < 0.05)
  p.ball[i,] = colMeans(p.ball_sim < 0.05 )
}

# plot
plot(x=n, y=p.cor[,1], type="b", pch=20, main="Y = X/4 + e", ylab='power', col='blue', ylim = c(0,1))
legend(x=160, y=0.4, legend = c("distance","ball"), lty=1:2, col = c('blue','red'))
lines(x = n, y=p.ball[,1], type="b", lty=2, col='red')
plot(x=n, y=p.cor[,2], type="b", pch=20, main="Y = X/4 * e", ylab='power', col='blue', ylim = c(0,1))
legend(x=160,y=0.4,legend = c("distance","ball"),lty=1:2, col = c('blue','red'))
lines(x = n, y=p.ball[,2], type="b", lty=2, col='red')
```

## Question
Implement a random walk Metropolis sampler for generating the standard Laplace distribution (see Exercise 3.2). For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.

## Answer
The density function of Laplace is $f(x)=0.5e^{-|x|},x\in R$.
```{r}
f=function(x) 0.5*exp(-abs(x))
```

In this simulation below, the Laplace densities in r(xi−1, y) will be computed by the f function write by myself.Then y is accepted or rejected and Xi generated by

   if (u[i] <= f(y, n) / f(x[i-1], n)) x[i] <- y
   else x[i] <- x[i-1]
   
These steps are combined into a function to generate the chain, given the parameters n and σ, initial value X0, and the length of the chain, N.

```{r}
rw.Metropolis <- function(sigma, x0, N) {
x <- numeric(N)
x[1] <- x0
u <- runif(N)
k <- 0
for (i in 2:N) {
y <- rnorm(1, x[i-1], sigma)
if (u[i] <= (f(y) / f(x[i-1]))) x[i] <- y 
else {
x[i] <- x[i-1]
k <- k + 1
}
}
return(list(x=x, k=k))
}
```

Four chains are generated for different variances σ2 of the proposal distribution.
```{r}
N <- 2000
sigma <- c(.05, .5, 2, 16)
x0 <- 25
rw1 <- rw.Metropolis( sigma[1], x0, N)
rw2 <- rw.Metropolis( sigma[2], x0, N)
rw3 <- rw.Metropolis( sigma[3], x0, N)
rw4 <- rw.Metropolis( sigma[4], x0, N)
#number of candidate points rejected
print(c(rw1$k, rw2$k, rw3$k, rw4$k))
```

Show the plots.
```{r}
library(GeneralizedHyperbolic)
refline <- qskewlap(c(.025, .975),param=c(0,1,1))
rw <- cbind(rw1$x, rw2$x, rw3$x, rw4$x)
for (j in 1:4) {
plot(rw[,j], type="l",
xlab=bquote(sigma == .(round(sigma[j],3))),
ylab="X", ylim=range(rw[,j]))
abline(h=refline)
}
```


## Conclusion
Only the third chain has a rejection rate in the range [0.15, 0.5].In the first plot with σ = 0.05, the ratios r(Xt, Y ) tend to be large and almost every candidate point is accepted. The increments are small and the chain is almost like a true random walk. Chain 1 has not converged to the target in 2000 iterations. The chain in the second plot generated with σ = 0.5 is converging very slowly and requires a much longer burn-in period. In the third plot (σ = 2) the chain is mixing well and converging to the target
distribution after a short burn-in period of about 500. Finally, in the fourth plot, where σ = 16, the ratios r(Xt, Y ) are smaller and most of the candidate points are rejected. The fourth chain converges, but it is inefficient.

## Question1
The natural logarithm and exponential functions are inverses of each other, so that mathematically log(exp x) = exp(log x) = x. Show by example that this property does not hold exactly in computer arithmetic. Does the identity hold with near equality? (See all.equal.)

## Answer1
### computer arithmetic

```{r}
f1 = function(x) log(exp(x))
f2 = function(x) exp(log(x))
x=1:10
f1(x) == f2(x)
f1(x) == x
f2(x) == x
```
### Use "isTRUE" with near equality

```{r}
c(isTRUE(all.equal(f1(x),f2(x))),isTRUE(all.equal(f1(x),x)),isTRUE(all.equal(f2(x),x)))
```

### conclusion

By example that this property does not hold exactly in computer arithmetic. The identity hold with near equality. (See all.equal.)

## Question2
Write a function to solve the equation 
$$\frac{2 \Gamma\left(\frac{k}{2}\right)}{\sqrt{\pi(k-1)} \Gamma\left(\frac{k-1}{2}\right)} \int_{0}^{c_{k-1}}\left(1+\frac{u^{2}}{k-1}\right)^{-k / 2} d u\\=\frac{2 \Gamma\left(\frac{k+1}{2}\right)}{\sqrt{\pi k} \Gamma\left(\frac{k}{2}\right)} \int_{0}^{c_{k}}\left(1+\frac{u^{2}}{k}\right)^{-(k+1) / 2} d u$$

for a, where
$$c_{k}=\sqrt{\frac{a^{2} k}{k+1-a^{2}}}$$

Compare the solutions with the points A(k) in Exercise 11.4.

## Answer2

Write a function f to express RHS in exercise11.5.
```{r}
f = function(a,k){
  c_k = sqrt(a^2*k/(k+1-a^2))
  c1 = 2*gamma((k+1)/2)
  c2 = sqrt(pi*k)*gamma(k/2)
  f_in = function(x) (1+x^2/k)^(-(k+1)/2)
  c3 = integrate(f=f_in,lower=0,upper=c_k)$value
  return(c1/c2*c3)
}
```

```{r}
k = c(4:25,100);n=length(k);
solution = numeric(n)
for(i in 1:n){
solution[i] = uniroot(function(a){f(a,k=k[i]-1)-f(a,k=k[i])},interval=c(-2,1))$root
}
library(knitr)
kable(cbind(k,solution),format="markdown")
```


Write a function s to express the equation in exercise11.4.
$$S_{k}(a)=P(t(k)>\sqrt{\frac{a^{2} k}{k+1-a^{2}}})$$

```{r}
s = function(a,k){
  q = sqrt(a^2*k/(k+1-a^2))
  s = pt(q,k)
  return(s)
}
```

Find the intersection points in exercise11.4.
```{r}
A_k = numeric(n)
for(i in 1:n){
  g2 = function(a) s(a,k[i]-1)-s(a,k[i])
  A_k[i] = uniroot(g2,interval=c(-2,1))$root
}
kable(cbind(k,A_k),format="markdown")
```

### compare
```{r}
kable(cbind(k,solution,A_k),format="markdown")
```

### conclusion
The solution in exercise11.5 are same to A(k) in exercise11.4.


## Question3
A-B-O blood type problem. Let the three alleles be A, B, and O with allele frequencies p,
q, and r. The 6 genotype frequencies under HWE and complete counts see in homework pdf.

Observed data: nA· = nAA + nAO = 28 (A-type),nB· = nBB + nBO = 24 (B-type), nOO = 41 (O-type),nAB = 70 (AB-type).

1.Use EM algorithm to solve MLE of p and q (consider missing data nAA and nBB).

2.Show that the log-maximum likelihood values in M-steps are increasing via line plot.

## Answer3

The complete data likelihood is:
$$L(p,q|n_{AA},n_{BB},n_{OO},n_{AO},n_{BO},n_{AB})=(p^2)^{n_{AA}}(q^2)^{n_{BB}}(r^2)^{n_{OO}}(2pr)^{n_{AO}}(2qr)^{n_{BO}}(2pq)^{n_{AB}}$$

The log-likelihood is:
$$l(p,q|n_{AA},n_{BB},n_{OO},n_{AO},n_{BO},n_{AB})=2n_{AA}log(p)+2n_{BB}log(q)+2n_{OO}log(r)+n_{AO}log(2pr)+n_{BO}log(2qr)+n_{AB}log(2pq)$$

The expert of the log-likelihood is:
$$E_{p_0,q_0}[l(p,q|n_{AA},n_{BB},n_{OO},n_{AO},n_{BO},n_{AB})]=\frac{2p_0}{p_0+2(1-p_0-q_0)}n_{A.}log(p)+\frac{2q_0}{q_0+2(1-p_0-q_0)}n_{B.}log(q)+2n_{OO}log(1-p-q)+\frac{2(1-p_0-q_0)}{p_0+2(1-p_0-q_0)}n_{A.}log(2p(1-p-q))+\frac{2(1-p_0-q_0)}{q_0+2(1-p_0-q_0)}n_{B.}log(2q(1-p-q))+n_{AB}log(2pq)$$


Now,begin the EM algorithm to solve the mle of p and q:
```{r}
nA=28;nB=24;nOO=41;nAB=70;
E_log=function(x0,x){p=x[1];q=x[2];p0=x0[1];q0=x0[2];
s=(2*p0/(p0+2*(1-p0-q0))*nA*log(p)+2*q0/(q0+2*(1-p0-q0))*nB*log(q)+2*nOO*log(1-p-q)+2*(1-p0-q0)/(p0+2*(1-p0-q0))*nA*log(2*p*(1-p-q))+2*(1-p0-q0)/(q0+2*(1-p0-q0))*nB*log(2*q*(1-p-q))+nAB*log(2*p*q))
return(-s)}
optim(c(0.3,0.4),E_log,x0=c(0.2,0.3))
```
### conclusion1
So the Mle of p is 0.3149542, the Mle of q is 0.3053138.

Show the log-maximum likelihood values in M-steps via line plot:
```{r}
M=numeric(51)
for(i in 1:51){
  M[i]=-optim(c(0.3,0.4),E_log,x0=c(0.2,0.3),control=list(maxit=i))$value
}
plot(M,type="l")
```

### conclusion2
The line plot shows that the log-maximum likelihood values in M-steps are increasing.

## Question1
 Use both for loops and lapply() to fit linear models to the mtcars using the formulas stored in this list:
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)

## Answer1
```{r}
x=mtcars;mpg=x$mpg;disp=x$disp;wt=x$wt
formulas <- list(
mpg ~ disp,
mpg ~ I(1 / disp),
mpg ~ disp + wt,
mpg ~ I(1 / disp) + wt
)
```

Use lapply() to fit linear models:
```{r}
out1=lapply(formulas,lm)
out1
```

Use for loops to fit linear models:
```{r}
out2=vector("list",length(formulas))
for(i in seq_along(formulas)){
  out2[[i]]=lm(formulas[[i]])
}
out2
```

### conclusion
As we can see, the results are equal.

## Question2
Fit the model mpg ~ disp to each of the bootstrap replicates of mtcars in the list below by using a for loop and lapply(). Can you do it without an anonymous function?
bootstraps <- lapply(1:10, function(i) {
rows <- sample(1:nrow(mtcars), rep = TRUE)
mtcars[rows, ]
})

## Answer2
```{r}
bootstraps <- lapply(1:10, function(i) {
rows <- sample(1:nrow(mtcars), rep = TRUE)
mtcars[rows, ]
})
out22=vector("list",length(bootstraps))
for(i in seq_along(bootstraps)){
mpg=bootstraps[[i]]$mpg;disp=bootstraps[[i]]$disp
formula2 <- list(mpg ~ disp)
out22[i]=lapply(formula2,lm)
}
out22
```

## Question3
For each model in the previous two exercises, extract R2 using the function below.
rsq <- function(mod) summary(mod)$r.squared

## Answer3
```{r}
rsq <- function(mod) summary(mod)$r.squared
lapply(out1,rsq)
lapply(out22,rsq)
```

## Question4
The following code simulates the performance of a t-test for non-normal data. Use sapply() and an anonymous function to extract the p-value from every trial.
trials <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)
Extra challenge: get rid of the anonymous function by using [[ directly.

## Answer4
```{r}
set.seed(12144)
trials <- replicate(
100,
t.test(rpois(10, 10), rpois(7, 10)),
simplify = FALSE
)
p <- function(x) x$p.value
out41=sapply(trials,p)
```

Extra challenge:get rid of the anonymous function by using [[ directly.
```{r}
out42=numeric(length(trials))
for(i in seq_along(trials)){
  out42[[i]]=trials[[i]]$p.value
}
```

Show all the results:
```{r}
library(knitr)
kable(cbind(out41[1:25],out42[1:25],out41[26:50],out42[26:50],out41[51:75],out42[51:75],out41[76:100],out42[76:100]),col.names=c("out41_1to25","out42_1to25","out41_25to50","out42_25to50","out41_51to75","out42_51to75","out41_76to100","out42_76to100"))
```

The results of two methods are same.

## Question5
Implement mcsapply(), a multicore version of sapply(). Can you implement mcvapply(), a parallel version of vapply()? Why or why not?

## Answer5

For sapply:
```{r}
set.seed(121451)
fun <- function(x){
  return (x+1);
  }
system.time({
res <- sapply(1:5000000, fun);
})
```

Implement mcsapply(), a multicore version of sapply():
```{r}
library(parallel)
set.seed(12145)
mcsapply=function(x,f){
cl <- makeCluster(getOption("cl.cores", 4))
  time=system.time({
  res <- parLapply(cl, x, f)
  })
 stopCluster(cl)
 return(list(res=res,time=time))
}
mcsapply(1:5000000,fun)$time
```

The elapse of mcsapply is smaller than sapply.

I can't implement mcvapply(), a parallel version of vapply().Because there is no function like "mcvapply" or "parVapply" .So we can't preset return value type.

## Queation1
You have already written an R function for Exercise 9.4 (page 277, Statistical Computing with R). Rewrite an Rcpp function for the same task. 

## Answer1
For R:
```{r}
f_r=function(x) 0.5*exp(-abs(x))
rw.Metropolis <- function(sigma, x0, N) {
x <- numeric(N)
x[1] <- x0
u <- runif(N)
k <- 0
for (i in 2:N) {
y <- rnorm(1, x[i-1], sigma)
if (u[i] <= (f_r(y) / f_r(x[i-1]))) x[i] <- y 
else {
x[i] <- x[i-1]
k <- k + 1
}
}
return(list(x=x, k=k))
}
```

For C:
```{r}
library(Rcpp)
cppFunction('List rwM(double sigma, double x0, int N) {
NumericVector x(N);
x[0]=x0;
int k=0;
for(int i=1;i<N;++i){
double u=runif(1)[0];
double y=rnorm(1,x[i-1],sigma)[0];
if (u<=exp(abs(x[i-1])-abs(y))) {x[i]=y;k=k+1;}
else x[i]=x[i-1];
}
List s=List::create(x,k);
return s;
}')
```

## Question2
Compare the generated random numbers by the two functions using qqplot.

## Answer2
```{r}
set.seed(12252)
N <- 2000
sigma <- c(0.5, 2, 7,16)
x0 <- 25
rw11 <- rw.Metropolis( sigma[1], x0, N)
rw21 <- rw.Metropolis( sigma[2], x0, N)
rw31 <- rw.Metropolis( sigma[3], x0, N)
rw41 <- rw.Metropolis( sigma[4], x0, N)
rw12 <- rwM( sigma[1], x0, N)
rw22 <- rwM( sigma[2], x0, N)
rw32 <- rwM( sigma[3], x0, N)
rw42 <- rwM( sigma[4], x0, N)
```

```{r}
rw1 <- cbind(rw11$x, rw21$x, rw31$x, rw41$x)
rw2 <- cbind(rw12[[1]], rw22[[1]], rw32[[1]], rw42[[1]])
for(i in 1:4){
qqplot(rw1[,i],rw2[,i],xlab="R",ylab="cpp")
abline(0,1,col="red")
}
```

## Question3
Campare the computation time of the two functions with microbenchmark.

## Answer3
```{r}
library(microbenchmark)
ts <- microbenchmark(rw11 <- rw.Metropolis( sigma[1], x0, N),
rw21 <- rw.Metropolis( sigma[2], x0, N),
rw31 <- rw.Metropolis( sigma[3], x0, N),
rw41 <- rw.Metropolis( sigma[4], x0, N),
rw12 <- rwM( sigma[1], x0, N),
rw22 <- rwM( sigma[2], x0, N),
rw32 <- rwM( sigma[3], x0, N),
rw42 <- rwM( sigma[4], x0, N))
summary(ts)[,c(1,3,5,6)]
```

## Question4
Comments your results.

## Answer4
In the qqplot,The data don't match very well between R and Rcpp.But the difference is not far.

The computation time of Rcpp is less than R.Rcpp is so fast.


